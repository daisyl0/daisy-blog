---
title: 字符编码小结
date: 2016-07-17 22:26:05
tags:
---

不总结一下字符编码，感觉对不起这些年我踩过的坑们。

## 字符编码

字符编码可以理解为一张一对一的码表，ascii码表即最常见的码表之一，中国常用字符编码的关系可以参考下图。

![字符编码](/img/unicode.png)

美国人可真强势，自己享受1字节，让众多非英语国家，unicode编码从2字节变为2~4字节。中文大多数为3字节。

## GBK

你一定对GB2312，GBK，GB1080一堆的玩意不陌生。GB的意思是国标。是在unicode之前中国自己搞的一套编码。具体来说就是这样的。

![gbk发展](/img/gbk.png)

在GB2312阶段，要求2个字节都大于127, 这样，中文汉字与ascii表字符是很好区分的。但这样表示的汉字数量有限，不够发挥啊，所以到GBK阶段，放弃了第2字节必须大于127的要求。这样一来，表示所有汉字倒是够了，但从此以后，中英文夹杂的GBK编码，只能先判断是不是大于127，如果是，我跳一位，如果不是，认为是英文。这简直是***万坑之源！！！***

![gbk跳](/img/gbk1.png)

从此以后，买张cd看真的好难！

更别提字符分隔这等事件了，如果你的日志是用竖线分隔，如果你的日志包含中文，如果你的中文是gbk编码，那么。。。我劝你还是转了utf-8再分隔吧。。。

```python
>>> s="滕华弢|海青"
>>> s
'\xeb\xf8\xbb\xaa\x8f||\xba\xa3\xc7\xe0'
>>> x=s.split('|')
['\xeb\xf8\xbb\xaa\x8f', '', '\xba\xa3\xc7\xe0']
>>> print x[0]
滕华�
>>> print x[2]
海青
```

上面的”弢“字，gbk编码为0x8f7c，第2字节编码恰好与分隔线“|”重合了。分隔之后，直接分隔就会导致以上错误。

## UTF-8

#### 编码

unicode到utf-16的转换很简单，一对一。到utf-8遵循以下规则。

```bash
unicode
UTF-8
0000 - 007F
0xxxxxxx
0080 - 07FF
110xxxxx 10xxxxxx
0800 - FFFF
1110xxxx 10xxxxxx 10xxxxxx
```

例如"汉"字的Unicode编码是6C49。6C49在0800-FFFF之间，所以要用3字节模板：1110xxxx 10xxxxxx 10xxxxxx。将6C49写成二进制是：0110 1100 0100 1001，将这个比特流按三字节模板的分段方法分为0110 110001 001001，依次代替模板中的x，得到：1110-0110 10-110001 10-001001，即E6 B1 89，这就是其UTF8的编码。

#### BOM

BOM(Byte Order Mark).保存文件的时候不会保存编码格式，打开文件时，却需要解码。这时就有很多麻烦。bom就是utf引入，在文档开头写bom，标识自己的编码格式。

```bash
BOM_UTF8 '\xef\xbb\xbf' 
BOM_UTF16_LE '\xff\xfe' 
BOM_UTF16_BE '\xfe\xff'
```

并不是所有的编辑器都写入bom，这种编辑器会采用一种默认格式解码，不成功再换另外一种。

#### UTF-8还是UTF8?####

可能在很多地方，你发现utf8,UTF8,utf-8,UTF-8都能用。到底哪个是对的呢？首先大小写是忽略的。UTF-8是标准名字，UTF8是别名，有些语言和场合定义了这个别名，但有些没有。所以用 UTF-8总是保险的。个人发现python,mysql,linux的iconv用二者都可以，node.js的iconv-lite只能用utf-8。

## GBK与UTF-8的转换

从上面的介绍可以知道：GBK是一张码表。unicode是一张码表。UTF-8是基于unicode的一种编码方式GBK到unicode可以查表得到, unicode到UTF-8可以按规则转换。

![encodedecode](/img/endecode.png)













