---
title: 字符编码小结
date: 2016-07-17 22:26:05
tags:
---

不总结一下字符编码，感觉对不起这些年我踩过的坑们。

所有的python基于2.x

## 字符编码

字符编码可以理解为一张一对一的码表，ascii码表即最常见的码表之一，中国常用字符编码的关系可以参考下图。

![字符编码](/img/unicode.png)

美国人可真强势，自己享受1字节，让众多非英语国家，unicode编码从2字节变为2~4字节。中文大多数为3字节。

## GBK

你一定对GB2312，GBK，GB1080一堆的玩意不陌生。GB的意思是国标。是在unicode之前中国自己搞的一套编码。具体来说就是这样的。

![gbk发展](/img/gbk.png)

在GB2312阶段，要求2个字节都大于127, 这样，中文汉字与ascii表字符是很好区分的。但这样表示的汉字数量有限，不够发挥啊，所以到GBK阶段，放弃了第2字节必须大于127的要求。这样一来，表示所有汉字倒是够了，但从此以后，中英文夹杂的GBK编码，只能先判断是不是大于127，如果是，我跳一位，如果不是，认为是英文。这简直是***万坑之源！！！***

![gbk跳](/img/gbk1.png)

从此以后，买张cd看真的好难！

更别提字符分隔这等事件了，如果你的日志是用竖线分隔，如果你的日志包含中文，如果你的中文是gbk编码，那么。。。我劝你还是转了utf-8再分隔吧。。。

```python
>>> s="滕华弢|海青"
>>> s
'\xeb\xf8\xbb\xaa\x8f||\xba\xa3\xc7\xe0'
>>> x=s.split('|')
['\xeb\xf8\xbb\xaa\x8f', '', '\xba\xa3\xc7\xe0']
>>> print x[0]
滕华�
>>> print x[2]
海青
```

上面的”弢“字，gbk编码为0x8f7c，第2字节编码恰好与分隔线“|”重合了。分隔之后，直接分隔就会导致以上错误。

BIG5是大混战时期，台湾，香港，澳门等地采用的繁体编码。

## UTF-8

#### 编码

unicode到utf-16的转换很简单，一对一。到utf-8遵循以下规则。

```bash
unicode
UTF-8
0000 - 007F
0xxxxxxx
0080 - 07FF
110xxxxx 10xxxxxx
0800 - FFFF
1110xxxx 10xxxxxx 10xxxxxx
```

例如"汉"字的Unicode编码是6C49。6C49在0800-FFFF之间，所以要用3字节模板：1110xxxx 10xxxxxx 10xxxxxx。将6C49写成二进制是：0110 1100 0100 1001，将这个比特流按三字节模板的分段方法分为0110 110001 001001，依次代替模板中的x，得到：1110-0110 10-110001 10-001001，即E6 B1 89，这就是其UTF8的编码。

#### BOM

BOM(Byte Order Mark).保存文件的时候不会保存编码格式，打开文件时，却需要解码。这时就有很多麻烦。bom就是utf引入，在文档开头写bom，标识自己的编码格式。

```bash
BOM_UTF8 '\xef\xbb\xbf' 
BOM_UTF16_LE '\xff\xfe' 
BOM_UTF16_BE '\xfe\xff'
```

并不是所有的编辑器都写入bom，这种编辑器会采用一种默认格式解码，不成功再换另外一种。

#### UTF-8还是UTF8?####

可能在很多地方，你发现utf8,UTF8,utf-8,UTF-8都能用。到底哪个是对的呢？首先大小写是忽略的。UTF-8是标准名字，UTF8是别名，有些语言和场合定义了这个别名，但有些没有。所以用 UTF-8总是保险的。个人发现python,mysql,linux的iconv用二者都可以，node.js的iconv-lite只能用utf-8。

## GBK与UTF-8的转换

从上面的介绍可以知道：GBK是一张码表。unicode是一张码表。UTF-8是基于unicode的一种编码方式。GBK到unicode可以查表得到, unicode到UTF-8可以按规则转换。

![encodedecode](/img/endecode.png)

有了以上知识，想要编解码就有点谱了。

## python中的字符编码

### 是str还是unicode?

先看下面一段代码

```python
>>> x='你好'
>>> x
'\xe4\xbd\xa0\xe5\xa5\xbd'
>>> x.decode('utf-8').encode('gbk')  #x为str
'\xc4\xe3\xba\xc3'

>>> y=u'你好'           #y为unicode
>>> y
u'\u4f60\u597d'
>>> y.encode('gbk')
'\xc4\xe3\xba\xc3'

>>> len(x)     #x为字节串
6
>>> len(y)    #y为字符串
2
```

上面的x和y，在转换为gbk编码的时候，分别是

x.decode('utf-8').encode('gbk') 

y.encode('gbk')

区别就在于前面的u，如果声明的时候不加u, 默认是文档声明的编码串(我的环境为utf-8)，如果加u,则为unicode串。值得注意的是，如果在写.py文件的时候不声明编码，默认为ascii, 则不支持中文。

如果不带u声明, str其实是字节串，它是unicode经过编码后的字节组成的序列。上例是len(x)=6

带u声明，unicode是字符串，上例中y一共有2个unicode编码，len(y)=2

### 编码声明

.py文件中，如果有用到非ASCII字符，则需要在文件头部进行字符编码的声明

```python
#-- coding: UTF-8 --
#-- coding: GBK --
```

### 读写文件

内置的open操作str，写入读出都要编码后再操作，直接操作unicode会报错。

```python
# coding: UTF-8
f = open('test.txt')
s = f.read()
f.close()
print type(s) # <type 'str'>
# 已知是GBK编码，解码成unicode
u = s.decode('GBK')
f = open('test.txt', 'w')
# 编码成UTF-8编码的str
# f.write(u) 报错
f.write(u.encode('UTF-8'))
f.close()
```

模块codecs提供了一个open()方法，可操作unicode，可自动编解码。推荐使用。

打开时，可以指定一个编码打开文件，使用这个方法打开的文件读取返回的将是unicode。

写入时，如果参数是unicode，则使用open()时指定的编码进行编码后写入；如果是str，则先根据源代码文件声明的字符编码，解码成unicode后再进行前述操作。

```python
# coding: GBK

import codecs
 
f = codecs.open('test.txt', encoding='UTF-8')
u = f.read()
f.close()
print type(u) # <type 'unicode'>
 
f = codecs.open('test.txt', 'a', encoding='UTF-8')
# 写入unicode，自动编码为utf-8
f.write(u)
 
# 写入str，自动进行解码编码操作
# GBK编码的str
s = '你好'
print repr(s) # '\xba\xba'
# 这里会先将GBK编码的str解码为unicode再编码为UTF-8写入
f.write(s) 
f.close()
```

## Node.js中的编码

Node.js中的字符串都是utf-8。引入iconv-lite等模块处理gbk.

```javascript
> var iconv=require('iconv-lite')
> s='你好'
'你好'
>utfbuf=new Buffer(s)
<Buffer e4 bd a0 e5 a5 bd>  //utf-8 buffer

> gbkbuf=iconv.encode(s,'gbk') //encode为gbk buffer
<Buffer c4 e3 ba c3>
  
```

gbk编码只能以Buffer保存。转换为字符串打印或者传参都会乱码。

```javascript
> console.log(String(utfs))
你好
> console.log(String(gbks)) //啊呀，我要崩溃了. gbk是个什么鬼，我不认识
����
```

如果要发送给前端，直接写buffer。只用调用res.setEncoding就好了。

```javascript
res.write(gbks)
res.setEncoding('utf-8')
res.end()
```

## 倆眼不识‘锟斤拷’

我不信有谁没见过 ‘锟斤拷’。

要想见到‘锟斤拷’很简单，只用在编码为gbk的shell中，开启node。随意地写上2个汉字，都会变成‘锟斤拷’。或者在nodepad++中，先设编码为utf8。把��复印进去。再将编码设为ANSI。‘锟斤拷’就出现啦。

```javascript
> s='锟斤拷锟斤拷'
'锟斤拷锟斤拷'
> new Buffer(s)
<Buffer ef bf bd ef bf bd ef bf bd ef bf bd>
```

产生的原因是utf-8对认识的编码，采用一个固定编码 0xefbfbd 替换。打印出来就是�。如果不巧用gbk来解码。二个�� 0xefbfbd 0xefbfbd，在gbk看来就是0xefbf锟 0xbdef斤 0xbfbd拷。



mysql中的编码那更是知识更多，坑更多。

所知有限，先总结到这里了。

.

